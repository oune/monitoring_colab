{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJi9F3nfUlbbXLlMWPgTHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f37aa2540e14e37b452f9fff0c59b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11f7d6c979ac4118866e4317d07bccce",
              "IPY_MODEL_90f890fb21654bcb850e25d02c608db6",
              "IPY_MODEL_ccfb3d44aa3841f7b1baf242d0727b4a"
            ],
            "layout": "IPY_MODEL_73f693a7f7b64c30b3e0200fd9b94222"
          }
        },
        "11f7d6c979ac4118866e4317d07bccce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bfa263022bd4a70b9e7774cbdb31ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_dd6695e33a4049bfb4989c1e13517f88",
            "value": "testing: 100%"
          }
        },
        "90f890fb21654bcb850e25d02c608db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcad1bf3a276433e829af48aeb832a6c",
            "max": 13894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9952277913884ca4ad9f2e54e78ab03c",
            "value": 13894
          }
        },
        "ccfb3d44aa3841f7b1baf242d0727b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c255449d3eb545af94d05871bcd53d8b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e54577e86144de4a720312ee4c55ba8",
            "value": " 13894/13894 [00:41&lt;00:00, 410.87it/s]"
          }
        },
        "73f693a7f7b64c30b3e0200fd9b94222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfa263022bd4a70b9e7774cbdb31ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6695e33a4049bfb4989c1e13517f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcad1bf3a276433e829af48aeb832a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9952277913884ca4ad9f2e54e78ab03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c255449d3eb545af94d05871bcd53d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e54577e86144de4a720312ee4c55ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oune/monitoring_colab/blob/main/ae_lstm_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmk_CTVQJ4WA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import easydict\n",
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAYDvea3_XXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 인코더\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size=4096, hidden_size=1024, num_layers=2):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                            dropout=0.1, bidirectional=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs, (hidden, cell) = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        return (hidden, cell)\n",
        "    \n",
        "## 디코더\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size=4096, hidden_size=1024, output_size=4096, num_layers=2):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                            dropout=0.1, bidirectional=False)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        output, (hidden, cell) = self.lstm(x, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        prediction = self.fc(output)\n",
        "\n",
        "        return prediction, (hidden, cell)\n",
        "    \n",
        "## LSTM Auto Encoder\n",
        "class LSTMAutoEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 latent_dim: int,\n",
        "                 window_size: int=1,\n",
        "                 **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        :param input_dim: 변수 Tag 갯수\n",
        "        :param latent_dim: 최종 압축할 차원 크기\n",
        "        :param window_size: 길이\n",
        "        :param kwargs:\n",
        "        \"\"\"\n",
        "\n",
        "        super(LSTMAutoEncoder, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.window_size = window_size\n",
        "\n",
        "        if \"num_layers\" in kwargs:\n",
        "            num_layers = kwargs.pop(\"num_layers\")\n",
        "        else:\n",
        "            num_layers = 1\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=latent_dim,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.reconstruct_decoder = Decoder(\n",
        "            input_size=input_dim,\n",
        "            output_size=input_dim,\n",
        "            hidden_size=latent_dim,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "\n",
        "    def forward(self, src:torch.Tensor, **kwargs):\n",
        "        batch_size, sequence_length, var_length = src.size()\n",
        "\n",
        "        ## Encoder 넣기\n",
        "        encoder_hidden = self.encoder(src)\n",
        "        \n",
        "        inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
        "        reconstruct_output = []\n",
        "        temp_input = torch.zeros((batch_size, 1, var_length), dtype=torch.float).to(src.device)\n",
        "        hidden = encoder_hidden\n",
        "        for t in range(sequence_length):\n",
        "            temp_input, hidden = self.reconstruct_decoder(temp_input, hidden)\n",
        "            reconstruct_output.append(temp_input)\n",
        "        reconstruct_output = torch.cat(reconstruct_output, dim=1)[:, inv_idx, :]\n",
        "        \n",
        "        return [reconstruct_output, src]\n",
        "\n",
        "    def loss_function(self,\n",
        "                      *args,\n",
        "                      **kwargs) -> dict:\n",
        "        recons = args[0]\n",
        "        input = args[1]\n",
        "        \n",
        "        ## MSE loss(Mean squared Error)\n",
        "        loss =F.mse_loss(recons, input)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "qBrAlzfOJ_rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvuRKxkaKU2g",
        "outputId": "459da779-fd0e-454b-a9f1-c8403e041a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/Othercomputers/내 노트북/부직포 압출장비/'"
      ],
      "metadata": {
        "id": "ooDyJUTHKUXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 설정 폴더\n",
        "args = easydict.EasyDict({\n",
        "    \"batch_size\": 128, ## 배치 사이즈 설정\n",
        "    \"device\": torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'), ## GPU 사용 여부 설정\n",
        "    \"input_size\": 3, ## 입력 차원 설정\n",
        "    \"latent_size\": 1, ## Hidden 차원 설정\n",
        "    \"output_size\": 3, ## 출력 차원 설정\n",
        "    \"window_size\" : 3, ## sequence Lenght\n",
        "    \"num_layers\": 2,     ## LSTM layer 갯수 설정\n",
        "    \"learning_rate\" : 0.001, ## learning rate 설정\n",
        "    \"max_iter\" : 100000, ## 총 반복 횟수 설정\n",
        "    'early_stop' : True,  ## valid loss가 작아지지 않으면 early stop 조건 설정\n",
        "})\n"
      ],
      "metadata": {
        "id": "LTbqlYnbOczo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'model8.pth'\n",
        "model_path = os.path.join(root, model_name)\n",
        "model = LSTMAutoEncoder(input_dim=args.input_size, latent_dim=args.latent_size, window_size=args.window_size, num_layers=args.num_layers)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(args.device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz79-KMlOXZ2",
        "outputId": "d8cd8caa-56b8-4a3b-8648-563c2301178c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMAutoEncoder(\n",
              "  (encoder): Encoder(\n",
              "    (lstm): LSTM(3, 1, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  )\n",
              "  (reconstruct_decoder): Decoder(\n",
              "    (lstm): LSTM(3, 1, num_layers=2, batch_first=True, dropout=0.1)\n",
              "    (relu): ReLU()\n",
              "    (fc): Linear(in_features=1, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/Othercomputers/내 노트북/부직포 압출장비/data.csv', index_col=0)"
      ],
      "metadata": {
        "id": "BH6iXT8LQL25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터를 불러올 때 index로 불러오기\n",
        "def make_data_idx(dates, window_size=1):\n",
        "    input_idx = []\n",
        "    for idx in range(window_size-1, len(dates)):\n",
        "        input_idx.append(list(range(idx - window_size+1, idx+1)))  \n",
        "    return input_idx"
      ],
      "metadata": {
        "id": "7JoU59ZH_xbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = make_data_idx(df.index.to_list(), window_size=args.window_size)\n",
        "selected_column = [item for item in df.columns][:args.input_size]\n",
        "var_data = torch.tensor(df[selected_column].values.astype(np.float), dtype=torch.float)\n",
        "idx = 1\n",
        "temp_input_ids = input_ids[idx]\n",
        "input_values = var_data[temp_input_ids]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPb97icC_0py",
        "outputId": "d635e0f8-5f1a-48a5-e9c7-0e20da0f40d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-fd10a6a8a8f8>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  var_data = torch.tensor(df[selected_column].values.astype(np.float), dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gPOGyzkBeIs",
        "outputId": "002f81ce-bbed-46a6-dfa7-58b0f1073c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -21.7688, -308.8175, -701.6309],\n",
              "        [ -21.7739, -363.2509, -534.2027],\n",
              "        [ -21.7729, -260.5415, -830.6281]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_values.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThnQhtRHCH3f",
        "outputId": "e9d5d191-1935-47b8-e860-6d0b4a3723ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(df, start, end):\n",
        "  ## 정규화\n",
        "  if df is not None:\n",
        "      mean_df = df.mean()\n",
        "      std_df = df.std()\n",
        "      df = (df-mean_df)/std_df\n",
        "\n",
        "  ## 연속한 index를 기준으로 학습에 사용합니다.\n",
        "  index_list = df.index.to_list()\n",
        "  input_ids = make_data_idx(index_list, window_size=args.window_size)\n",
        "\n",
        "  var_data = torch.tensor(df.astype(np.float), dtype=torch.float)\n",
        "  \n",
        "  return torch.stack([var_data[input_ids[idx]] for i in range(start, end)], dim=1)"
      ],
      "metadata": {
        "id": "fibgDrROkG7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset을 상속받아 데이터를 구성\n",
        "class TagDataset(Dataset):\n",
        "    def __init__(self, input_size, df, mean_df=None, std_df = None, window_size=1):\n",
        "        \n",
        "        ## 변수 갯수\n",
        "        self.input_size = input_size\n",
        "        \n",
        "        ## 복원할 sequence 길이\n",
        "        self.window_size = window_size\n",
        "        \n",
        "        ## Summary용 데이터 Deep copy\n",
        "        original_df = df.copy()\n",
        "        \n",
        "        ## 정규화\n",
        "        if mean_df is not None and std_df is not None:\n",
        "            sensor_columns = [item for item in df.columns]\n",
        "            df[sensor_columns] = (df[sensor_columns]-mean_df)/std_df\n",
        "        \n",
        "        ## 연속한 index를 기준으로 학습에 사용합니다.\n",
        "        index_list = df.index.to_list()\n",
        "        self.input_ids = make_data_idx(index_list, window_size=window_size)\n",
        "        \n",
        "        ## sensor 데이터만 사용하여 reconstruct에 활용\n",
        "        self.selected_column = [item for item in df.columns][:input_size]\n",
        "        self.var_data = torch.tensor(df[self.selected_column].values.astype(np.float), dtype=torch.float)\n",
        "        \n",
        "        ## Summary 용\n",
        "        self.df = original_df.iloc[np.array(self.input_ids)[:, -1]]\n",
        "        \n",
        "    ## Dataset은 반드시 __len__ 함수를 만들어줘야함(데이터 길이)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    ## Dataset은 반드시 __getitem__ 함수를 만들어줘야함\n",
        "    ## torch 모듈은 __getitem__ 을 호출하여 학습할 데이터를 불러옴.\n",
        "    def __getitem__(self, item):\n",
        "        temp_input_ids = self.input_ids[item]\n",
        "        input_values = self.var_data[temp_input_ids]\n",
        "        return input_values"
      ],
      "metadata": {
        "id": "3UwbNXH0E5we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_list(args, model, test_loader):\n",
        "    test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\")\n",
        "    loss_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch_data in test_iterator:\n",
        "                \n",
        "            batch_data = batch_data.to(args.device)\n",
        "            predict_values = model(batch_data)\n",
        "            \n",
        "            ## MAE(Mean Absolute Error)로 계산\n",
        "            loss = F.l1_loss(predict_values[0], predict_values[1], reduce=False)\n",
        "            #loss = loss.sum(dim=2).sum(dim=1).cpu().numpy()\n",
        "            loss = loss.mean(dim=1).cpu().numpy()\n",
        "            loss_list.append(loss)\n",
        "    loss_list = np.concatenate(loss_list, axis=0)\n",
        "    return loss_list"
      ],
      "metadata": {
        "id": "bm7bbfnJPw2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_df = df.mean()\n",
        "std_df = df.std()"
      ],
      "metadata": {
        "id": "bPl-j2KxdIo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TagDataset(df=df, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)"
      ],
      "metadata": {
        "id": "mLiWQIvDF42O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4bab0e-2796-4d5d-91b0-b645fd7a3c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-462d755f23d0>:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.var_data = torch.tensor(df[self.selected_column].values.astype(np.float), dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=dataset,\n",
        "                 batch_size=args.batch_size,\n",
        "                 shuffle=False)"
      ],
      "metadata": {
        "id": "-hhrWz4cGBdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = get_loss_list(args, model, train_loader)\n",
        "mean = np.mean(loss_list, axis=0)\n",
        "std = np.cov(loss_list.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "0f37aa2540e14e37b452f9fff0c59b76",
            "11f7d6c979ac4118866e4317d07bccce",
            "90f890fb21654bcb850e25d02c608db6",
            "ccfb3d44aa3841f7b1baf242d0727b4a",
            "73f693a7f7b64c30b3e0200fd9b94222",
            "8bfa263022bd4a70b9e7774cbdb31ed2",
            "dd6695e33a4049bfb4989c1e13517f88",
            "dcad1bf3a276433e829af48aeb832a6c",
            "9952277913884ca4ad9f2e54e78ab03c",
            "c255449d3eb545af94d05871bcd53d8b",
            "6e54577e86144de4a720312ee4c55ba8"
          ]
        },
        "id": "VvGtkikhPm5x",
        "outputId": "471ecc38-0b0b-457e-e21e-aca532fbe392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "testing:   0%|          | 0/13894 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f37aa2540e14e37b452f9fff0c59b76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Anomaly Score\n",
        "class Anomaly_Calculator:\n",
        "    def __init__(self, mean:np.array, std:np.array):\n",
        "        assert mean.shape[0] == std.shape[0] and mean.shape[0] == std.shape[1], '평균과 분산의 차원이 똑같아야 합니다.'\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "    \n",
        "    def __call__(self, recons_error:np.array):\n",
        "        x = (recons_error-self.mean)\n",
        "        return np.matmul(np.matmul(x, self.std), x.T)\n",
        "\n",
        "## 비정상 점수 계산기\n",
        "anomaly_calculator = Anomaly_Calculator(mean, std)"
      ],
      "metadata": {
        "id": "akAUBjZhG53v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oneData = iter(train_loader).next()\n",
        "oneData = model(oneData.to(args.device))"
      ],
      "metadata": {
        "id": "ixvlFtsyg9Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "with torch.no_grad():  \n",
        "  predict_values = oneData\n",
        "  loss = F.l1_loss(predict_values[0], predict_values[1], reduce=False)\n",
        "  loss = loss.mean(dim=1).cpu().numpy()\n",
        "  loss_list.append(loss)\n",
        "\n",
        "loss_list = np.concatenate(loss_list, axis=0)\n",
        "ans_score = anomaly_calculator(loss_list).mean()\n",
        "ans_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFH0PBMcg1FC",
        "outputId": "2f74b029-95b2-460e-8c81-55edd8387cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18104747994509568"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실제 데이터를 이용하여 결과를 내도록 개발"
      ],
      "metadata": {
        "id": "ILB_FFACfRty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oneData = iter(train_loader).next()\n",
        "# print(oneData)\n",
        "print(len(oneData))\n",
        "print()\n",
        "res = model(oneData.to(args.device))\n",
        "# print(oneData)\n",
        "print(len(res))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJCHwMXKcnjJ",
        "outputId": "14d13a58-1cd6-497d-ac4e-f53d53d3c043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oneData[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3_tF0JMdW4Y",
        "outputId": "04d9af50-9f63-4278-8386-1f85762aabd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6300, -0.9033, -0.5847],\n",
              "         [ 0.6331, -0.8772, -0.5333],\n",
              "         [ 0.6250, -0.9986, -0.3913]],\n",
              "\n",
              "        [[ 0.6331, -0.8772, -0.5333],\n",
              "         [ 0.6250, -0.9986, -0.3913],\n",
              "         [ 0.6265, -0.7694, -0.6427]]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXTv04JCip4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}